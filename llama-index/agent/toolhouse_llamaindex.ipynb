{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"https://colab.research.google.com/gist/iamdaniele/84cca60019384c4159df28e14e2dc61c/toolhouse-llamaindex-workflow.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sales Prospecting Workflow with Toolhouse\n",
    "\n",
    "In this notebook you'll learn how to create a sales prospecting workflow using Toolhouse and LlamaIndex. Sales prospecting allows companies to find the perfect potential customer based on the business's value proposition and target market.\n",
    "\n",
    "The workflow will use a single agent to perform these activities:\n",
    "\n",
    "1. It will ask the agent to determine a business's value proposition by getting the contents of its landing page.\n",
    "1. It will search the internet for prospective customers that may benefit from the business's offerings.\n",
    "1. It will determine the best company to reach out to.\n",
    "1. It will draft a personalized email to the selected company.\n",
    "\n",
    "## Initial setup\n",
    "\n",
    "Let's make sure all the required libraries are present. This example uses Llama 3.2 on Groq, but you can use any the LLMs supported by LlamaIndex."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting llama-index\n",
      "  Downloading llama_index-0.12.19-py3-none-any.whl.metadata (12 kB)\n",
      "Requirement already satisfied: llama-index-agent-openai<0.5.0,>=0.4.0 in /home/vscode/.local/lib/python3.11/site-packages (from llama-index) (0.4.6)\n",
      "Collecting llama-index-cli<0.5.0,>=0.4.0 (from llama-index)\n",
      "  Downloading llama_index_cli-0.4.0-py3-none-any.whl.metadata (1.5 kB)\n",
      "Requirement already satisfied: llama-index-core<0.13.0,>=0.12.19 in /home/vscode/.local/lib/python3.11/site-packages (from llama-index) (0.12.19)\n",
      "Requirement already satisfied: llama-index-embeddings-openai<0.4.0,>=0.3.0 in /home/vscode/.local/lib/python3.11/site-packages (from llama-index) (0.3.1)\n",
      "Collecting llama-index-indices-managed-llama-cloud>=0.4.0 (from llama-index)\n",
      "  Downloading llama_index_indices_managed_llama_cloud-0.6.7-py3-none-any.whl.metadata (3.6 kB)\n",
      "Requirement already satisfied: llama-index-llms-openai<0.4.0,>=0.3.0 in /home/vscode/.local/lib/python3.11/site-packages (from llama-index) (0.3.20)\n",
      "Collecting llama-index-multi-modal-llms-openai<0.5.0,>=0.4.0 (from llama-index)\n",
      "  Downloading llama_index_multi_modal_llms_openai-0.4.3-py3-none-any.whl.metadata (726 bytes)\n",
      "Collecting llama-index-program-openai<0.4.0,>=0.3.0 (from llama-index)\n",
      "  Downloading llama_index_program_openai-0.3.1-py3-none-any.whl.metadata (764 bytes)\n",
      "Collecting llama-index-question-gen-openai<0.4.0,>=0.3.0 (from llama-index)\n",
      "  Downloading llama_index_question_gen_openai-0.3.0-py3-none-any.whl.metadata (783 bytes)\n",
      "Collecting llama-index-readers-file<0.5.0,>=0.4.0 (from llama-index)\n",
      "  Downloading llama_index_readers_file-0.4.5-py3-none-any.whl.metadata (5.4 kB)\n",
      "Collecting llama-index-readers-llama-parse>=0.4.0 (from llama-index)\n",
      "  Downloading llama_index_readers_llama_parse-0.4.0-py3-none-any.whl.metadata (3.6 kB)\n",
      "Requirement already satisfied: nltk>3.8.1 in /home/vscode/.local/lib/python3.11/site-packages (from llama-index) (3.9.1)\n",
      "Requirement already satisfied: openai>=1.14.0 in /home/vscode/.local/lib/python3.11/site-packages (from llama-index-agent-openai<0.5.0,>=0.4.0->llama-index) (1.63.2)\n",
      "Requirement already satisfied: PyYAML>=6.0.1 in /usr/local/python/current/lib/python3.11/site-packages (from llama-index-core<0.13.0,>=0.12.19->llama-index) (6.0.2)\n",
      "Requirement already satisfied: SQLAlchemy>=1.4.49 in /home/vscode/.local/lib/python3.11/site-packages (from SQLAlchemy[asyncio]>=1.4.49->llama-index-core<0.13.0,>=0.12.19->llama-index) (2.0.38)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.6 in /home/vscode/.local/lib/python3.11/site-packages (from llama-index-core<0.13.0,>=0.12.19->llama-index) (3.11.12)\n",
      "Requirement already satisfied: dataclasses-json in /home/vscode/.local/lib/python3.11/site-packages (from llama-index-core<0.13.0,>=0.12.19->llama-index) (0.6.7)\n",
      "Requirement already satisfied: deprecated>=1.2.9.3 in /home/vscode/.local/lib/python3.11/site-packages (from llama-index-core<0.13.0,>=0.12.19->llama-index) (1.2.18)\n",
      "Requirement already satisfied: dirtyjson<2.0.0,>=1.0.8 in /home/vscode/.local/lib/python3.11/site-packages (from llama-index-core<0.13.0,>=0.12.19->llama-index) (1.0.8)\n",
      "Requirement already satisfied: filetype<2.0.0,>=1.2.0 in /home/vscode/.local/lib/python3.11/site-packages (from llama-index-core<0.13.0,>=0.12.19->llama-index) (1.2.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /home/vscode/.local/lib/python3.11/site-packages (from llama-index-core<0.13.0,>=0.12.19->llama-index) (2025.2.0)\n",
      "Requirement already satisfied: httpx in /usr/local/python/current/lib/python3.11/site-packages (from llama-index-core<0.13.0,>=0.12.19->llama-index) (0.28.1)\n",
      "Requirement already satisfied: nest-asyncio<2.0.0,>=1.5.8 in /home/vscode/.local/lib/python3.11/site-packages (from llama-index-core<0.13.0,>=0.12.19->llama-index) (1.6.0)\n",
      "Requirement already satisfied: networkx>=3.0 in /home/vscode/.local/lib/python3.11/site-packages (from llama-index-core<0.13.0,>=0.12.19->llama-index) (3.4.2)\n",
      "Requirement already satisfied: numpy in /home/vscode/.local/lib/python3.11/site-packages (from llama-index-core<0.13.0,>=0.12.19->llama-index) (2.2.3)\n",
      "Requirement already satisfied: pillow>=9.0.0 in /home/vscode/.local/lib/python3.11/site-packages (from llama-index-core<0.13.0,>=0.12.19->llama-index) (11.1.0)\n",
      "Requirement already satisfied: pydantic>=2.8.0 in /home/vscode/.local/lib/python3.11/site-packages (from llama-index-core<0.13.0,>=0.12.19->llama-index) (2.10.6)\n",
      "Requirement already satisfied: requests>=2.31.0 in /usr/local/python/current/lib/python3.11/site-packages (from llama-index-core<0.13.0,>=0.12.19->llama-index) (2.32.3)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.2.0 in /home/vscode/.local/lib/python3.11/site-packages (from llama-index-core<0.13.0,>=0.12.19->llama-index) (9.0.0)\n",
      "Requirement already satisfied: tiktoken>=0.3.3 in /home/vscode/.local/lib/python3.11/site-packages (from llama-index-core<0.13.0,>=0.12.19->llama-index) (0.9.0)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.66.1 in /home/vscode/.local/lib/python3.11/site-packages (from llama-index-core<0.13.0,>=0.12.19->llama-index) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions>=4.5.0 in /home/vscode/.local/lib/python3.11/site-packages (from llama-index-core<0.13.0,>=0.12.19->llama-index) (4.12.2)\n",
      "Requirement already satisfied: typing-inspect>=0.8.0 in /home/vscode/.local/lib/python3.11/site-packages (from llama-index-core<0.13.0,>=0.12.19->llama-index) (0.9.0)\n",
      "Requirement already satisfied: wrapt in /home/vscode/.local/lib/python3.11/site-packages (from llama-index-core<0.13.0,>=0.12.19->llama-index) (1.17.2)\n",
      "Collecting llama-cloud<0.2.0,>=0.1.8 (from llama-index-indices-managed-llama-cloud>=0.4.0->llama-index)\n",
      "  Downloading llama_cloud-0.1.12-py3-none-any.whl.metadata (851 bytes)\n",
      "Collecting beautifulsoup4<5.0.0,>=4.12.3 (from llama-index-readers-file<0.5.0,>=0.4.0->llama-index)\n",
      "  Downloading beautifulsoup4-4.13.3-py3-none-any.whl.metadata (3.8 kB)\n",
      "Collecting pandas (from llama-index-readers-file<0.5.0,>=0.4.0->llama-index)\n",
      "  Downloading pandas-2.2.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (89 kB)\n",
      "Collecting pypdf<6.0.0,>=5.1.0 (from llama-index-readers-file<0.5.0,>=0.4.0->llama-index)\n",
      "  Downloading pypdf-5.3.0-py3-none-any.whl.metadata (7.2 kB)\n",
      "Collecting striprtf<0.0.27,>=0.0.26 (from llama-index-readers-file<0.5.0,>=0.4.0->llama-index)\n",
      "  Downloading striprtf-0.0.26-py3-none-any.whl.metadata (2.1 kB)\n",
      "Collecting llama-parse>=0.5.0 (from llama-index-readers-llama-parse>=0.4.0->llama-index)\n",
      "  Downloading llama_parse-0.6.1-py3-none-any.whl.metadata (6.9 kB)\n",
      "Requirement already satisfied: click in /home/vscode/.local/lib/python3.11/site-packages (from nltk>3.8.1->llama-index) (8.1.8)\n",
      "Requirement already satisfied: joblib in /home/vscode/.local/lib/python3.11/site-packages (from nltk>3.8.1->llama-index) (1.4.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /home/vscode/.local/lib/python3.11/site-packages (from nltk>3.8.1->llama-index) (2024.11.6)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /home/vscode/.local/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.13.0,>=0.12.19->llama-index) (2.4.6)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /home/vscode/.local/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.13.0,>=0.12.19->llama-index) (1.3.2)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/python/current/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.13.0,>=0.12.19->llama-index) (25.1.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /home/vscode/.local/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.13.0,>=0.12.19->llama-index) (1.5.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /home/vscode/.local/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.13.0,>=0.12.19->llama-index) (6.1.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /home/vscode/.local/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.13.0,>=0.12.19->llama-index) (0.2.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /home/vscode/.local/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.13.0,>=0.12.19->llama-index) (1.18.3)\n",
      "Collecting soupsieve>1.2 (from beautifulsoup4<5.0.0,>=4.12.3->llama-index-readers-file<0.5.0,>=0.4.0->llama-index)\n",
      "  Downloading soupsieve-2.6-py3-none-any.whl.metadata (4.6 kB)\n",
      "Requirement already satisfied: certifi>=2024.7.4 in /usr/local/python/current/lib/python3.11/site-packages (from llama-cloud<0.2.0,>=0.1.8->llama-index-indices-managed-llama-cloud>=0.4.0->llama-index) (2025.1.31)\n",
      "Requirement already satisfied: anyio in /usr/local/python/current/lib/python3.11/site-packages (from httpx->llama-index-core<0.13.0,>=0.12.19->llama-index) (4.8.0)\n",
      "Requirement already satisfied: httpcore==1.* in /usr/local/python/current/lib/python3.11/site-packages (from httpx->llama-index-core<0.13.0,>=0.12.19->llama-index) (1.0.7)\n",
      "Requirement already satisfied: idna in /usr/local/python/current/lib/python3.11/site-packages (from httpx->llama-index-core<0.13.0,>=0.12.19->llama-index) (3.10)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/python/current/lib/python3.11/site-packages (from httpcore==1.*->httpx->llama-index-core<0.13.0,>=0.12.19->llama-index) (0.14.0)\n",
      "Collecting llama-cloud-services>=0.6.1 (from llama-parse>=0.5.0->llama-index-readers-llama-parse>=0.4.0->llama-index)\n",
      "  Downloading llama_cloud_services-0.6.1-py3-none-any.whl.metadata (2.7 kB)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /home/vscode/.local/lib/python3.11/site-packages (from openai>=1.14.0->llama-index-agent-openai<0.5.0,>=0.4.0->llama-index) (1.9.0)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in /home/vscode/.local/lib/python3.11/site-packages (from openai>=1.14.0->llama-index-agent-openai<0.5.0,>=0.4.0->llama-index) (0.8.2)\n",
      "Requirement already satisfied: sniffio in /usr/local/python/current/lib/python3.11/site-packages (from openai>=1.14.0->llama-index-agent-openai<0.5.0,>=0.4.0->llama-index) (1.3.1)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /home/vscode/.local/lib/python3.11/site-packages (from pydantic>=2.8.0->llama-index-core<0.13.0,>=0.12.19->llama-index) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.2 in /home/vscode/.local/lib/python3.11/site-packages (from pydantic>=2.8.0->llama-index-core<0.13.0,>=0.12.19->llama-index) (2.27.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/python/current/lib/python3.11/site-packages (from requests>=2.31.0->llama-index-core<0.13.0,>=0.12.19->llama-index) (3.4.1)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/python/current/lib/python3.11/site-packages (from requests>=2.31.0->llama-index-core<0.13.0,>=0.12.19->llama-index) (2.3.0)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in /home/vscode/.local/lib/python3.11/site-packages (from SQLAlchemy>=1.4.49->SQLAlchemy[asyncio]>=1.4.49->llama-index-core<0.13.0,>=0.12.19->llama-index) (3.1.1)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in /home/vscode/.local/lib/python3.11/site-packages (from typing-inspect>=0.8.0->llama-index-core<0.13.0,>=0.12.19->llama-index) (1.0.0)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /home/vscode/.local/lib/python3.11/site-packages (from dataclasses-json->llama-index-core<0.13.0,>=0.12.19->llama-index) (3.26.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /home/vscode/.local/lib/python3.11/site-packages (from pandas->llama-index-readers-file<0.5.0,>=0.4.0->llama-index) (2.9.0.post0)\n",
      "Collecting pytz>=2020.1 (from pandas->llama-index-readers-file<0.5.0,>=0.4.0->llama-index)\n",
      "  Downloading pytz-2025.1-py2.py3-none-any.whl.metadata (22 kB)\n",
      "Collecting tzdata>=2022.7 (from pandas->llama-index-readers-file<0.5.0,>=0.4.0->llama-index)\n",
      "  Downloading tzdata-2025.1-py2.py3-none-any.whl.metadata (1.4 kB)\n",
      "Collecting python-dotenv<2.0.0,>=1.0.1 (from llama-cloud-services>=0.6.1->llama-parse>=0.5.0->llama-index-readers-llama-parse>=0.4.0->llama-index)\n",
      "  Downloading python_dotenv-1.0.1-py3-none-any.whl.metadata (23 kB)\n",
      "Requirement already satisfied: packaging>=17.0 in /home/vscode/.local/lib/python3.11/site-packages (from marshmallow<4.0.0,>=3.18.0->dataclasses-json->llama-index-core<0.13.0,>=0.12.19->llama-index) (24.2)\n",
      "Requirement already satisfied: six>=1.5 in /home/vscode/.local/lib/python3.11/site-packages (from python-dateutil>=2.8.2->pandas->llama-index-readers-file<0.5.0,>=0.4.0->llama-index) (1.17.0)\n",
      "Downloading llama_index-0.12.19-py3-none-any.whl (7.0 kB)\n",
      "Downloading llama_index_cli-0.4.0-py3-none-any.whl (27 kB)\n",
      "Downloading llama_index_indices_managed_llama_cloud-0.6.7-py3-none-any.whl (13 kB)\n",
      "Downloading llama_index_multi_modal_llms_openai-0.4.3-py3-none-any.whl (5.9 kB)\n",
      "Downloading llama_index_program_openai-0.3.1-py3-none-any.whl (5.3 kB)\n",
      "Downloading llama_index_question_gen_openai-0.3.0-py3-none-any.whl (2.9 kB)\n",
      "Downloading llama_index_readers_file-0.4.5-py3-none-any.whl (39 kB)\n",
      "Downloading llama_index_readers_llama_parse-0.4.0-py3-none-any.whl (2.5 kB)\n",
      "Downloading beautifulsoup4-4.13.3-py3-none-any.whl (186 kB)\n",
      "Downloading llama_cloud-0.1.12-py3-none-any.whl (252 kB)\n",
      "Downloading llama_parse-0.6.1-py3-none-any.whl (4.8 kB)\n",
      "Downloading pypdf-5.3.0-py3-none-any.whl (300 kB)\n",
      "Downloading striprtf-0.0.26-py3-none-any.whl (6.9 kB)\n",
      "Downloading pandas-2.2.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (13.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.1/13.1 MB\u001b[0m \u001b[31m58.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading llama_cloud_services-0.6.1-py3-none-any.whl (22 kB)\n",
      "Downloading pytz-2025.1-py2.py3-none-any.whl (507 kB)\n",
      "Downloading soupsieve-2.6-py3-none-any.whl (36 kB)\n",
      "Downloading tzdata-2025.1-py2.py3-none-any.whl (346 kB)\n",
      "Downloading python_dotenv-1.0.1-py3-none-any.whl (19 kB)\n",
      "Installing collected packages: striprtf, pytz, tzdata, soupsieve, python-dotenv, pypdf, pandas, beautifulsoup4, llama-cloud, llama-index-readers-file, llama-index-indices-managed-llama-cloud, llama-cloud-services, llama-parse, llama-index-multi-modal-llms-openai, llama-index-cli, llama-index-readers-llama-parse, llama-index-program-openai, llama-index-question-gen-openai, llama-index\n",
      "Successfully installed beautifulsoup4-4.13.3 llama-cloud-0.1.12 llama-cloud-services-0.6.1 llama-index-0.12.19 llama-index-cli-0.4.0 llama-index-indices-managed-llama-cloud-0.6.7 llama-index-multi-modal-llms-openai-0.4.3 llama-index-program-openai-0.3.1 llama-index-question-gen-openai-0.3.0 llama-index-readers-file-0.4.5 llama-index-readers-llama-parse-0.4.0 llama-parse-0.6.1 pandas-2.2.3 pypdf-5.3.0 python-dotenv-1.0.1 pytz-2025.1 soupsieve-2.6 striprtf-0.0.26 tzdata-2025.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Collecting llama-index-llms-groq\n",
      "  Downloading llama_index_llms_groq-0.3.1-py3-none-any.whl.metadata (2.3 kB)\n",
      "Requirement already satisfied: llama-index-core<0.13.0,>=0.12.0 in /home/vscode/.local/lib/python3.11/site-packages (from llama-index-llms-groq) (0.12.19)\n",
      "Collecting llama-index-llms-openai-like<0.4.0,>=0.3.1 (from llama-index-llms-groq)\n",
      "  Downloading llama_index_llms_openai_like-0.3.3-py3-none-any.whl.metadata (751 bytes)\n",
      "Requirement already satisfied: PyYAML>=6.0.1 in /usr/local/python/current/lib/python3.11/site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-llms-groq) (6.0.2)\n",
      "Requirement already satisfied: SQLAlchemy>=1.4.49 in /home/vscode/.local/lib/python3.11/site-packages (from SQLAlchemy[asyncio]>=1.4.49->llama-index-core<0.13.0,>=0.12.0->llama-index-llms-groq) (2.0.38)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.6 in /home/vscode/.local/lib/python3.11/site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-llms-groq) (3.11.12)\n",
      "Requirement already satisfied: dataclasses-json in /home/vscode/.local/lib/python3.11/site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-llms-groq) (0.6.7)\n",
      "Requirement already satisfied: deprecated>=1.2.9.3 in /home/vscode/.local/lib/python3.11/site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-llms-groq) (1.2.18)\n",
      "Requirement already satisfied: dirtyjson<2.0.0,>=1.0.8 in /home/vscode/.local/lib/python3.11/site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-llms-groq) (1.0.8)\n",
      "Requirement already satisfied: filetype<2.0.0,>=1.2.0 in /home/vscode/.local/lib/python3.11/site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-llms-groq) (1.2.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /home/vscode/.local/lib/python3.11/site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-llms-groq) (2025.2.0)\n",
      "Requirement already satisfied: httpx in /usr/local/python/current/lib/python3.11/site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-llms-groq) (0.28.1)\n",
      "Requirement already satisfied: nest-asyncio<2.0.0,>=1.5.8 in /home/vscode/.local/lib/python3.11/site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-llms-groq) (1.6.0)\n",
      "Requirement already satisfied: networkx>=3.0 in /home/vscode/.local/lib/python3.11/site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-llms-groq) (3.4.2)\n",
      "Requirement already satisfied: nltk>3.8.1 in /home/vscode/.local/lib/python3.11/site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-llms-groq) (3.9.1)\n",
      "Requirement already satisfied: numpy in /home/vscode/.local/lib/python3.11/site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-llms-groq) (2.2.3)\n",
      "Requirement already satisfied: pillow>=9.0.0 in /home/vscode/.local/lib/python3.11/site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-llms-groq) (11.1.0)\n",
      "Requirement already satisfied: pydantic>=2.8.0 in /home/vscode/.local/lib/python3.11/site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-llms-groq) (2.10.6)\n",
      "Requirement already satisfied: requests>=2.31.0 in /usr/local/python/current/lib/python3.11/site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-llms-groq) (2.32.3)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.2.0 in /home/vscode/.local/lib/python3.11/site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-llms-groq) (9.0.0)\n",
      "Requirement already satisfied: tiktoken>=0.3.3 in /home/vscode/.local/lib/python3.11/site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-llms-groq) (0.9.0)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.66.1 in /home/vscode/.local/lib/python3.11/site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-llms-groq) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions>=4.5.0 in /home/vscode/.local/lib/python3.11/site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-llms-groq) (4.12.2)\n",
      "Requirement already satisfied: typing-inspect>=0.8.0 in /home/vscode/.local/lib/python3.11/site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-llms-groq) (0.9.0)\n",
      "Requirement already satisfied: wrapt in /home/vscode/.local/lib/python3.11/site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-llms-groq) (1.17.2)\n",
      "Requirement already satisfied: llama-index-llms-openai<0.4.0,>=0.3.9 in /home/vscode/.local/lib/python3.11/site-packages (from llama-index-llms-openai-like<0.4.0,>=0.3.1->llama-index-llms-groq) (0.3.20)\n",
      "Collecting transformers<5.0.0,>=4.37.0 (from llama-index-llms-openai-like<0.4.0,>=0.3.1->llama-index-llms-groq)\n",
      "  Downloading transformers-4.49.0-py3-none-any.whl.metadata (44 kB)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /home/vscode/.local/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.13.0,>=0.12.0->llama-index-llms-groq) (2.4.6)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /home/vscode/.local/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.13.0,>=0.12.0->llama-index-llms-groq) (1.3.2)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/python/current/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.13.0,>=0.12.0->llama-index-llms-groq) (25.1.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /home/vscode/.local/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.13.0,>=0.12.0->llama-index-llms-groq) (1.5.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /home/vscode/.local/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.13.0,>=0.12.0->llama-index-llms-groq) (6.1.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /home/vscode/.local/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.13.0,>=0.12.0->llama-index-llms-groq) (0.2.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /home/vscode/.local/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.13.0,>=0.12.0->llama-index-llms-groq) (1.18.3)\n",
      "Requirement already satisfied: openai<2.0.0,>=1.58.1 in /home/vscode/.local/lib/python3.11/site-packages (from llama-index-llms-openai<0.4.0,>=0.3.9->llama-index-llms-openai-like<0.4.0,>=0.3.1->llama-index-llms-groq) (1.63.2)\n",
      "Requirement already satisfied: click in /home/vscode/.local/lib/python3.11/site-packages (from nltk>3.8.1->llama-index-core<0.13.0,>=0.12.0->llama-index-llms-groq) (8.1.8)\n",
      "Requirement already satisfied: joblib in /home/vscode/.local/lib/python3.11/site-packages (from nltk>3.8.1->llama-index-core<0.13.0,>=0.12.0->llama-index-llms-groq) (1.4.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /home/vscode/.local/lib/python3.11/site-packages (from nltk>3.8.1->llama-index-core<0.13.0,>=0.12.0->llama-index-llms-groq) (2024.11.6)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /home/vscode/.local/lib/python3.11/site-packages (from pydantic>=2.8.0->llama-index-core<0.13.0,>=0.12.0->llama-index-llms-groq) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.2 in /home/vscode/.local/lib/python3.11/site-packages (from pydantic>=2.8.0->llama-index-core<0.13.0,>=0.12.0->llama-index-llms-groq) (2.27.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/python/current/lib/python3.11/site-packages (from requests>=2.31.0->llama-index-core<0.13.0,>=0.12.0->llama-index-llms-groq) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/python/current/lib/python3.11/site-packages (from requests>=2.31.0->llama-index-core<0.13.0,>=0.12.0->llama-index-llms-groq) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/python/current/lib/python3.11/site-packages (from requests>=2.31.0->llama-index-core<0.13.0,>=0.12.0->llama-index-llms-groq) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/python/current/lib/python3.11/site-packages (from requests>=2.31.0->llama-index-core<0.13.0,>=0.12.0->llama-index-llms-groq) (2025.1.31)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in /home/vscode/.local/lib/python3.11/site-packages (from SQLAlchemy>=1.4.49->SQLAlchemy[asyncio]>=1.4.49->llama-index-core<0.13.0,>=0.12.0->llama-index-llms-groq) (3.1.1)\n",
      "Collecting filelock (from transformers<5.0.0,>=4.37.0->llama-index-llms-openai-like<0.4.0,>=0.3.1->llama-index-llms-groq)\n",
      "  Downloading filelock-3.17.0-py3-none-any.whl.metadata (2.9 kB)\n",
      "Collecting huggingface-hub<1.0,>=0.26.0 (from transformers<5.0.0,>=4.37.0->llama-index-llms-openai-like<0.4.0,>=0.3.1->llama-index-llms-groq)\n",
      "  Downloading huggingface_hub-0.28.1-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/vscode/.local/lib/python3.11/site-packages (from transformers<5.0.0,>=4.37.0->llama-index-llms-openai-like<0.4.0,>=0.3.1->llama-index-llms-groq) (24.2)\n",
      "Collecting tokenizers<0.22,>=0.21 (from transformers<5.0.0,>=4.37.0->llama-index-llms-openai-like<0.4.0,>=0.3.1->llama-index-llms-groq)\n",
      "  Downloading tokenizers-0.21.0-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
      "Collecting safetensors>=0.4.1 (from transformers<5.0.0,>=4.37.0->llama-index-llms-openai-like<0.4.0,>=0.3.1->llama-index-llms-groq)\n",
      "  Downloading safetensors-0.5.2-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.8 kB)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in /home/vscode/.local/lib/python3.11/site-packages (from typing-inspect>=0.8.0->llama-index-core<0.13.0,>=0.12.0->llama-index-llms-groq) (1.0.0)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /home/vscode/.local/lib/python3.11/site-packages (from dataclasses-json->llama-index-core<0.13.0,>=0.12.0->llama-index-llms-groq) (3.26.1)\n",
      "Requirement already satisfied: anyio in /usr/local/python/current/lib/python3.11/site-packages (from httpx->llama-index-core<0.13.0,>=0.12.0->llama-index-llms-groq) (4.8.0)\n",
      "Requirement already satisfied: httpcore==1.* in /usr/local/python/current/lib/python3.11/site-packages (from httpx->llama-index-core<0.13.0,>=0.12.0->llama-index-llms-groq) (1.0.7)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/python/current/lib/python3.11/site-packages (from httpcore==1.*->httpx->llama-index-core<0.13.0,>=0.12.0->llama-index-llms-groq) (0.14.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /home/vscode/.local/lib/python3.11/site-packages (from openai<2.0.0,>=1.58.1->llama-index-llms-openai<0.4.0,>=0.3.9->llama-index-llms-openai-like<0.4.0,>=0.3.1->llama-index-llms-groq) (1.9.0)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in /home/vscode/.local/lib/python3.11/site-packages (from openai<2.0.0,>=1.58.1->llama-index-llms-openai<0.4.0,>=0.3.9->llama-index-llms-openai-like<0.4.0,>=0.3.1->llama-index-llms-groq) (0.8.2)\n",
      "Requirement already satisfied: sniffio in /usr/local/python/current/lib/python3.11/site-packages (from openai<2.0.0,>=1.58.1->llama-index-llms-openai<0.4.0,>=0.3.9->llama-index-llms-openai-like<0.4.0,>=0.3.1->llama-index-llms-groq) (1.3.1)\n",
      "Downloading llama_index_llms_groq-0.3.1-py3-none-any.whl (2.9 kB)\n",
      "Downloading llama_index_llms_openai_like-0.3.3-py3-none-any.whl (3.1 kB)\n",
      "Downloading transformers-4.49.0-py3-none-any.whl (10.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.0/10.0 MB\u001b[0m \u001b[31m56.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading huggingface_hub-0.28.1-py3-none-any.whl (464 kB)\n",
      "Downloading safetensors-0.5.2-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (461 kB)\n",
      "Downloading tokenizers-0.21.0-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.0/3.0 MB\u001b[0m \u001b[31m52.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading filelock-3.17.0-py3-none-any.whl (16 kB)\n",
      "Installing collected packages: safetensors, filelock, huggingface-hub, tokenizers, transformers, llama-index-llms-openai-like, llama-index-llms-groq\n",
      "Successfully installed filelock-3.17.0 huggingface-hub-0.28.1 llama-index-llms-groq-0.3.1 llama-index-llms-openai-like-0.3.3 safetensors-0.5.2 tokenizers-0.21.0 transformers-4.49.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Collecting toolhouse\n",
      "  Downloading toolhouse-1.3.1-py3-none-any.whl.metadata (23 kB)\n",
      "Collecting anthropic (from toolhouse)\n",
      "  Downloading anthropic-0.45.2-py3-none-any.whl.metadata (23 kB)\n",
      "Collecting groq (from toolhouse)\n",
      "  Downloading groq-0.18.0-py3-none-any.whl.metadata (14 kB)\n",
      "Collecting http-exceptions (from toolhouse)\n",
      "  Downloading http_exceptions-0.2.10-py3-none-any.whl.metadata (7.0 kB)\n",
      "Requirement already satisfied: llama-index in /usr/local/python/current/lib/python3.11/site-packages (from toolhouse) (0.12.19)\n",
      "Requirement already satisfied: openai in /home/vscode/.local/lib/python3.11/site-packages (from toolhouse) (1.63.2)\n",
      "Requirement already satisfied: python-dotenv>=1.0.1 in /usr/local/python/current/lib/python3.11/site-packages (from toolhouse) (1.0.1)\n",
      "Requirement already satisfied: requests in /usr/local/python/current/lib/python3.11/site-packages (from toolhouse) (2.32.3)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/python/current/lib/python3.11/site-packages (from anthropic->toolhouse) (4.8.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /home/vscode/.local/lib/python3.11/site-packages (from anthropic->toolhouse) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/python/current/lib/python3.11/site-packages (from anthropic->toolhouse) (0.28.1)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in /home/vscode/.local/lib/python3.11/site-packages (from anthropic->toolhouse) (0.8.2)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in /home/vscode/.local/lib/python3.11/site-packages (from anthropic->toolhouse) (2.10.6)\n",
      "Requirement already satisfied: sniffio in /usr/local/python/current/lib/python3.11/site-packages (from anthropic->toolhouse) (1.3.1)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.10 in /home/vscode/.local/lib/python3.11/site-packages (from anthropic->toolhouse) (4.12.2)\n",
      "Requirement already satisfied: llama-index-agent-openai<0.5.0,>=0.4.0 in /home/vscode/.local/lib/python3.11/site-packages (from llama-index->toolhouse) (0.4.6)\n",
      "Requirement already satisfied: llama-index-cli<0.5.0,>=0.4.0 in /usr/local/python/current/lib/python3.11/site-packages (from llama-index->toolhouse) (0.4.0)\n",
      "Requirement already satisfied: llama-index-core<0.13.0,>=0.12.19 in /home/vscode/.local/lib/python3.11/site-packages (from llama-index->toolhouse) (0.12.19)\n",
      "Requirement already satisfied: llama-index-embeddings-openai<0.4.0,>=0.3.0 in /home/vscode/.local/lib/python3.11/site-packages (from llama-index->toolhouse) (0.3.1)\n",
      "Requirement already satisfied: llama-index-indices-managed-llama-cloud>=0.4.0 in /usr/local/python/current/lib/python3.11/site-packages (from llama-index->toolhouse) (0.6.7)\n",
      "Requirement already satisfied: llama-index-llms-openai<0.4.0,>=0.3.0 in /home/vscode/.local/lib/python3.11/site-packages (from llama-index->toolhouse) (0.3.20)\n",
      "Requirement already satisfied: llama-index-multi-modal-llms-openai<0.5.0,>=0.4.0 in /usr/local/python/current/lib/python3.11/site-packages (from llama-index->toolhouse) (0.4.3)\n",
      "Requirement already satisfied: llama-index-program-openai<0.4.0,>=0.3.0 in /usr/local/python/current/lib/python3.11/site-packages (from llama-index->toolhouse) (0.3.1)\n",
      "Requirement already satisfied: llama-index-question-gen-openai<0.4.0,>=0.3.0 in /usr/local/python/current/lib/python3.11/site-packages (from llama-index->toolhouse) (0.3.0)\n",
      "Requirement already satisfied: llama-index-readers-file<0.5.0,>=0.4.0 in /usr/local/python/current/lib/python3.11/site-packages (from llama-index->toolhouse) (0.4.5)\n",
      "Requirement already satisfied: llama-index-readers-llama-parse>=0.4.0 in /usr/local/python/current/lib/python3.11/site-packages (from llama-index->toolhouse) (0.4.0)\n",
      "Requirement already satisfied: nltk>3.8.1 in /home/vscode/.local/lib/python3.11/site-packages (from llama-index->toolhouse) (3.9.1)\n",
      "Requirement already satisfied: tqdm>4 in /home/vscode/.local/lib/python3.11/site-packages (from openai->toolhouse) (4.67.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/python/current/lib/python3.11/site-packages (from requests->toolhouse) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/python/current/lib/python3.11/site-packages (from requests->toolhouse) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/python/current/lib/python3.11/site-packages (from requests->toolhouse) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/python/current/lib/python3.11/site-packages (from requests->toolhouse) (2025.1.31)\n",
      "Requirement already satisfied: httpcore==1.* in /usr/local/python/current/lib/python3.11/site-packages (from httpx<1,>=0.23.0->anthropic->toolhouse) (1.0.7)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/python/current/lib/python3.11/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->anthropic->toolhouse) (0.14.0)\n",
      "Requirement already satisfied: PyYAML>=6.0.1 in /usr/local/python/current/lib/python3.11/site-packages (from llama-index-core<0.13.0,>=0.12.19->llama-index->toolhouse) (6.0.2)\n",
      "Requirement already satisfied: SQLAlchemy>=1.4.49 in /home/vscode/.local/lib/python3.11/site-packages (from SQLAlchemy[asyncio]>=1.4.49->llama-index-core<0.13.0,>=0.12.19->llama-index->toolhouse) (2.0.38)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.6 in /home/vscode/.local/lib/python3.11/site-packages (from llama-index-core<0.13.0,>=0.12.19->llama-index->toolhouse) (3.11.12)\n",
      "Requirement already satisfied: dataclasses-json in /home/vscode/.local/lib/python3.11/site-packages (from llama-index-core<0.13.0,>=0.12.19->llama-index->toolhouse) (0.6.7)\n",
      "Requirement already satisfied: deprecated>=1.2.9.3 in /home/vscode/.local/lib/python3.11/site-packages (from llama-index-core<0.13.0,>=0.12.19->llama-index->toolhouse) (1.2.18)\n",
      "Requirement already satisfied: dirtyjson<2.0.0,>=1.0.8 in /home/vscode/.local/lib/python3.11/site-packages (from llama-index-core<0.13.0,>=0.12.19->llama-index->toolhouse) (1.0.8)\n",
      "Requirement already satisfied: filetype<2.0.0,>=1.2.0 in /home/vscode/.local/lib/python3.11/site-packages (from llama-index-core<0.13.0,>=0.12.19->llama-index->toolhouse) (1.2.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /home/vscode/.local/lib/python3.11/site-packages (from llama-index-core<0.13.0,>=0.12.19->llama-index->toolhouse) (2025.2.0)\n",
      "Requirement already satisfied: nest-asyncio<2.0.0,>=1.5.8 in /home/vscode/.local/lib/python3.11/site-packages (from llama-index-core<0.13.0,>=0.12.19->llama-index->toolhouse) (1.6.0)\n",
      "Requirement already satisfied: networkx>=3.0 in /home/vscode/.local/lib/python3.11/site-packages (from llama-index-core<0.13.0,>=0.12.19->llama-index->toolhouse) (3.4.2)\n",
      "Requirement already satisfied: numpy in /home/vscode/.local/lib/python3.11/site-packages (from llama-index-core<0.13.0,>=0.12.19->llama-index->toolhouse) (2.2.3)\n",
      "Requirement already satisfied: pillow>=9.0.0 in /home/vscode/.local/lib/python3.11/site-packages (from llama-index-core<0.13.0,>=0.12.19->llama-index->toolhouse) (11.1.0)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.2.0 in /home/vscode/.local/lib/python3.11/site-packages (from llama-index-core<0.13.0,>=0.12.19->llama-index->toolhouse) (9.0.0)\n",
      "Requirement already satisfied: tiktoken>=0.3.3 in /home/vscode/.local/lib/python3.11/site-packages (from llama-index-core<0.13.0,>=0.12.19->llama-index->toolhouse) (0.9.0)\n",
      "Requirement already satisfied: typing-inspect>=0.8.0 in /home/vscode/.local/lib/python3.11/site-packages (from llama-index-core<0.13.0,>=0.12.19->llama-index->toolhouse) (0.9.0)\n",
      "Requirement already satisfied: wrapt in /home/vscode/.local/lib/python3.11/site-packages (from llama-index-core<0.13.0,>=0.12.19->llama-index->toolhouse) (1.17.2)\n",
      "Requirement already satisfied: llama-cloud<0.2.0,>=0.1.8 in /usr/local/python/current/lib/python3.11/site-packages (from llama-index-indices-managed-llama-cloud>=0.4.0->llama-index->toolhouse) (0.1.12)\n",
      "Requirement already satisfied: beautifulsoup4<5.0.0,>=4.12.3 in /usr/local/python/current/lib/python3.11/site-packages (from llama-index-readers-file<0.5.0,>=0.4.0->llama-index->toolhouse) (4.13.3)\n",
      "Requirement already satisfied: pandas in /usr/local/python/current/lib/python3.11/site-packages (from llama-index-readers-file<0.5.0,>=0.4.0->llama-index->toolhouse) (2.2.3)\n",
      "Requirement already satisfied: pypdf<6.0.0,>=5.1.0 in /usr/local/python/current/lib/python3.11/site-packages (from llama-index-readers-file<0.5.0,>=0.4.0->llama-index->toolhouse) (5.3.0)\n",
      "Requirement already satisfied: striprtf<0.0.27,>=0.0.26 in /usr/local/python/current/lib/python3.11/site-packages (from llama-index-readers-file<0.5.0,>=0.4.0->llama-index->toolhouse) (0.0.26)\n",
      "Requirement already satisfied: llama-parse>=0.5.0 in /usr/local/python/current/lib/python3.11/site-packages (from llama-index-readers-llama-parse>=0.4.0->llama-index->toolhouse) (0.6.1)\n",
      "Requirement already satisfied: click in /home/vscode/.local/lib/python3.11/site-packages (from nltk>3.8.1->llama-index->toolhouse) (8.1.8)\n",
      "Requirement already satisfied: joblib in /home/vscode/.local/lib/python3.11/site-packages (from nltk>3.8.1->llama-index->toolhouse) (1.4.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /home/vscode/.local/lib/python3.11/site-packages (from nltk>3.8.1->llama-index->toolhouse) (2024.11.6)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /home/vscode/.local/lib/python3.11/site-packages (from pydantic<3,>=1.9.0->anthropic->toolhouse) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.2 in /home/vscode/.local/lib/python3.11/site-packages (from pydantic<3,>=1.9.0->anthropic->toolhouse) (2.27.2)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /home/vscode/.local/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.13.0,>=0.12.19->llama-index->toolhouse) (2.4.6)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /home/vscode/.local/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.13.0,>=0.12.19->llama-index->toolhouse) (1.3.2)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/python/current/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.13.0,>=0.12.19->llama-index->toolhouse) (25.1.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /home/vscode/.local/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.13.0,>=0.12.19->llama-index->toolhouse) (1.5.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /home/vscode/.local/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.13.0,>=0.12.19->llama-index->toolhouse) (6.1.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /home/vscode/.local/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.13.0,>=0.12.19->llama-index->toolhouse) (0.2.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /home/vscode/.local/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.13.0,>=0.12.19->llama-index->toolhouse) (1.18.3)\n",
      "Requirement already satisfied: soupsieve>1.2 in /usr/local/python/current/lib/python3.11/site-packages (from beautifulsoup4<5.0.0,>=4.12.3->llama-index-readers-file<0.5.0,>=0.4.0->llama-index->toolhouse) (2.6)\n",
      "Requirement already satisfied: llama-cloud-services>=0.6.1 in /usr/local/python/current/lib/python3.11/site-packages (from llama-parse>=0.5.0->llama-index-readers-llama-parse>=0.4.0->llama-index->toolhouse) (0.6.1)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in /home/vscode/.local/lib/python3.11/site-packages (from SQLAlchemy>=1.4.49->SQLAlchemy[asyncio]>=1.4.49->llama-index-core<0.13.0,>=0.12.19->llama-index->toolhouse) (3.1.1)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in /home/vscode/.local/lib/python3.11/site-packages (from typing-inspect>=0.8.0->llama-index-core<0.13.0,>=0.12.19->llama-index->toolhouse) (1.0.0)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /home/vscode/.local/lib/python3.11/site-packages (from dataclasses-json->llama-index-core<0.13.0,>=0.12.19->llama-index->toolhouse) (3.26.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /home/vscode/.local/lib/python3.11/site-packages (from pandas->llama-index-readers-file<0.5.0,>=0.4.0->llama-index->toolhouse) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/python/current/lib/python3.11/site-packages (from pandas->llama-index-readers-file<0.5.0,>=0.4.0->llama-index->toolhouse) (2025.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /usr/local/python/current/lib/python3.11/site-packages (from pandas->llama-index-readers-file<0.5.0,>=0.4.0->llama-index->toolhouse) (2025.1)\n",
      "Requirement already satisfied: packaging>=17.0 in /home/vscode/.local/lib/python3.11/site-packages (from marshmallow<4.0.0,>=3.18.0->dataclasses-json->llama-index-core<0.13.0,>=0.12.19->llama-index->toolhouse) (24.2)\n",
      "Requirement already satisfied: six>=1.5 in /home/vscode/.local/lib/python3.11/site-packages (from python-dateutil>=2.8.2->pandas->llama-index-readers-file<0.5.0,>=0.4.0->llama-index->toolhouse) (1.17.0)\n",
      "Downloading toolhouse-1.3.1-py3-none-any.whl (43 kB)\n",
      "Downloading anthropic-0.45.2-py3-none-any.whl (222 kB)\n",
      "Downloading groq-0.18.0-py3-none-any.whl (121 kB)\n",
      "Downloading http_exceptions-0.2.10-py3-none-any.whl (8.8 kB)\n",
      "Installing collected packages: http-exceptions, groq, anthropic, toolhouse\n",
      "Successfully installed anthropic-0.45.2 groq-0.18.0 http-exceptions-0.2.10 toolhouse-1.3.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install llama-index\n",
    "%pip install llama-index-llms-groq\n",
    "%pip install toolhouse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we'll pass the API keys.\n",
    "\n",
    "To get a Toolhouse API key:\n",
    "\n",
    "1. [Sign up for Toolhouse](https://join.toolhouse.ai) or [sign in](https://app.toolhouse.ai) if you're an existing user.\n",
    "2. If you're a new user, copy the auto-generated API key you'll receive during onboarding. Existing users can get an API key in the [API Keys page](https://app.toolhouse.ai/settings/api-keys).\n",
    "3. Paste the API bey below.\n",
    "\n",
    "To get a Groq API Key, [get access on Groq](https://console.groq.com), then past your API key below.\n",
    "\n",
    "**Important:** store your API keys safely when in production."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ[\n",
    "    \"TOOLHOUSE_API_KEY\"\n",
    "] = \"Get your Toolhouse API key at https://join.toolhouse.ai\"\n",
    "os.environ[\n",
    "    \"GROQ_API_KEY\"\n",
    "] = \"Get your Groq API key at https://console.groq.com\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import libraries\n",
    "\n",
    "We're going to import LlamaIndexas and Toolhouse. We then initialize Toolhouse and the Groq LLM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.llms.groq import Groq\n",
    "from llama_index.core.agent import ReActAgent\n",
    "from llama_index.core.memory import ChatMemoryBuffer\n",
    "from toolhouse import Toolhouse, Provider\n",
    "from llama_index.core.workflow import (\n",
    "    Context,\n",
    "    Event,\n",
    "    StartEvent,\n",
    "    StopEvent,\n",
    "    Workflow,\n",
    "    step,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = Groq(model=\"llama-3.2-11b-vision-preview\")\n",
    "\n",
    "th = Toolhouse(provider=Provider.LLAMAINDEX)\n",
    "th.set_metadata(\"id\", \"llamaindex_agent\")\n",
    "th.set_metadata(\"timezone\", 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Install Toolhouse tools\n",
    "\n",
    "The agent will require to search the web and get the contents of a page. To allow this, go to your [Toolhouse dashboard](https://app.toolhouse.ai) and install the following tools:\n",
    "\n",
    "- [Get page contents](https://app.toolhouse.ai/store/scraper)\n",
    "- [Web search](https://app.toolhouse.ai/store/web_search)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Workflow\n",
    "\n",
    "The workflow will have four steps; we created an output event for each step to make the sequential aspect clearer.\n",
    "\n",
    "Because Toolhouse integrates directly into LlamaIndex, you can pass the Toolhouse tools directly to the agent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class WebsiteContentEvent(Event):\n",
    "    contents: str\n",
    "\n",
    "\n",
    "class WebSearchEvent(Event):\n",
    "    results: str\n",
    "\n",
    "\n",
    "class RankingEvent(Event):\n",
    "    results: str\n",
    "\n",
    "\n",
    "class LogEvent(Event):\n",
    "    msg: str\n",
    "\n",
    "\n",
    "class SalesRepWorkflow(Workflow):\n",
    "    agent = ReActAgent(\n",
    "        tools=th.get_tools(bundle=\"llamaindex test\"),\n",
    "        llm=llm,\n",
    "        memory=ChatMemoryBuffer.from_defaults(),\n",
    "    )\n",
    "\n",
    "    @step\n",
    "    async def get_company_info(\n",
    "        self, ctx: Context, ev: StartEvent\n",
    "    ) -> WebsiteContentEvent:\n",
    "        ctx.write_event_to_stream(\n",
    "            LogEvent(msg=f\"Getting the contents of {ev.url}…\")\n",
    "        )\n",
    "        prompt = f\"Get the contents of {ev.url}, then summarize its key value propositions in a few bullet points.\"\n",
    "        contents = await self.agent.achat(prompt)\n",
    "        return WebsiteContentEvent(contents=str(contents.response))\n",
    "\n",
    "    @step\n",
    "    async def find_prospects(\n",
    "        self, ctx: Context, ev: WebsiteContentEvent\n",
    "    ) -> WebSearchEvent:\n",
    "        ctx.write_event_to_stream(\n",
    "            LogEvent(\n",
    "                msg=f\"Performing web searches to identify companies who can benefit from the business's offerings.\"\n",
    "            )\n",
    "        )\n",
    "        prompt = f\"With that you know about the business, perform a web search to find 5 tech companies who may benefit from the business's product. Only answer with the names of the companies you chose.\"\n",
    "        results = await self.agent.achat(prompt)\n",
    "        return WebSearchEvent(results=str(results.response))\n",
    "\n",
    "    @step\n",
    "    async def select_best_company(\n",
    "        self, ctx: Context, ev: WebSearchEvent\n",
    "    ) -> RankingEvent:\n",
    "        ctx.write_event_to_stream(\n",
    "            LogEvent(\n",
    "                msg=f\"Selecting the best company who can benefit from the business's offering…\"\n",
    "            )\n",
    "        )\n",
    "        prompt = \"Select one company that can benefit from the business's product. Only use your knowledge to select the company. Respond with just the name of the company. Do not use tools.\"\n",
    "        results = await self.agent.achat(prompt)\n",
    "        ctx.write_event_to_stream(\n",
    "            LogEvent(\n",
    "                msg=f\"The agent selected this company: {results.response}\"\n",
    "            )\n",
    "        )\n",
    "        return RankingEvent(results=str(results.response))\n",
    "\n",
    "    @step\n",
    "    async def prepare_email(self, ctx: Context, ev: RankingEvent) -> StopEvent:\n",
    "        ctx.write_event_to_stream(\n",
    "            LogEvent(msg=f\"Drafting a short email for sales outreach…\")\n",
    "        )\n",
    "        prompt = f\"Draft a short cold sales outreach email for the company you picked. Do not use tools.\"\n",
    "        email = await self.agent.achat(prompt)\n",
    "        ctx.write_event_to_stream(\n",
    "            LogEvent(msg=f\"Here is the email: {email.response}\")\n",
    "        )\n",
    "        return StopEvent(result=str(email.response))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run the workflow\n",
    "\n",
    "Simply instantiate the workflow and pass the URL of a company to get started."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting the contents of https://toolhouse.ai…\n",
      "Performing web searches to identify companies who can benefit from the business's offerings.\n",
      "Selecting the best company who can benefit from the business's offering…\n",
      "The agent selected this company: Cohere\n",
      "Drafting a short email for sales outreach…\n",
      "Here is the email: Subject: Streamline Your LLM Function Calling with Toolhouse\n",
      "\n",
      "Hi [Cohere Team],\n",
      "\n",
      "I noticed Cohere is leading the way in providing enterprise-ready LLM solutions. Given that your Command-r model already supports function calling, I thought you'd be interested in Toolhouse's developer toolkit that could enhance your clients' implementation experience.\n",
      "\n",
      "Toolhouse offers a unified SDK that streamlines LLM function calling across multiple models, including Cohere's. Our platform provides:\n",
      "- Pre-built, production-ready tools that reduce development time\n",
      "- Built-in analytics for easier debugging\n",
      "- A single integration point for multiple LLM tools\n",
      "\n",
      "Would you be open to a 15-minute call to discuss how Toolhouse could help Cohere's enterprise clients implement function calling more efficiently?\n",
      "\n",
      "Best regards,\n",
      "[Name]\n"
     ]
    }
   ],
   "source": [
    "workflow = SalesRepWorkflow(timeout=None)\n",
    "handler = workflow.run(url=\"https://toolhouse.ai\")\n",
    "async for event in handler.stream_events():\n",
    "    if isinstance(event, LogEvent):\n",
    "        print(event.msg)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "include_colab_link": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
